{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python: Data from the Web\n",
    "\n",
    "Name:Jordan Dever\n",
    "\n",
    "abc123: xfd461\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Write code to query http://duckduckgo.com/html/ with the key query \"data science\".  Parse the resulting page by returning all the **unique** web URLs. Return only the base URLs (http://duckduckgo.com, www.duckduckgo.com, ...)\n",
    "        \n",
    "hint: Use re.findall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd',\n",
       " 'http://www.w3.org/1999/xhtml',\n",
       " 'http://www.w3.org/1999/xhtml',\n",
       " 'http://www.w3.org/1999/xhtml',\n",
       " 'http://www.w3.org/1999/xhtml',\n",
       " 'https://duckduckgo.com/',\n",
       " 'http-equiv=',\n",
       " 'https://duckduckgo.com/']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.parse, urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "baseurl = \"http://duckduckgo.com/html/\"\n",
    "query = 'data science'\n",
    "parms = {'q':query}\n",
    "url = baseurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "file = urllib.request.urlopen(url)\n",
    "html_page = file.read().decode()\n",
    "\n",
    "re.findall(r\"www\\.[^\\\" \\n]+|http[^\\\" \\n]+\", html_page)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Find another table on Wikipedia and use the BeautifulSoup package to parse the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['CV', 'Generic aircraft carrier']\n",
      "['CVA', 'Attack carrier (up to 1975)']\n",
      "['CVB', 'Large aircraft carrier (retired 1952)']\n",
      "['CVAN', 'Nuclear-powered attack carrier']\n",
      "['CVE', 'Escort carrier']\n",
      "['CVHA', 'Aircraft carrier, Helicopter Assault (retired)']\n",
      "['CVHE', 'Aircraft carrier, Helicopter, Escort (retired)']\n",
      "['CVV', 'Aircraft Carrier (Medium) (proposed)']\n",
      "['CVL', 'Light aircraft carrier']\n",
      "['CVN', 'Nuclear-powered aircraft carrier']\n",
      "['CVS', 'Anti-submarine warfare carrier']\n",
      "['CVT', 'Training Aircraft Carrier']\n",
      "['CVU', 'Utility carrier (retired)']\n",
      "['LHA', 'Landing helicopter assault, a type of amphibious assault ship']\n",
      "['LHD', 'Landing helicopter dock, a type of amphibious assault ship']\n",
      "['LPH', 'Landing platform helicopter, a type of amphibious assault ship']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup # External Python package\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Aircraft_carrier' # Example: You can use this or find another one.\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "myTable = soup.find('table',{'class':'wikitable'})\n",
    "tbody = myTable.find('tbody')\n",
    "rows = tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    print(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1971', 'Film Fun', 'Writer, Director, Producer, Co-Host', '']\n",
      "['1977', 'Just Like Magic', 'Writer, Director, Producer', '']\n",
      "['1987', 'Undershorts: The Movie[22]', 'Writer, Director, Producer', 'Appears as himself in the short \"A Canadian Werewolf in Hollywood\"']\n",
      "['1994', 'Turn of the Blade', 'Director, Writer (story), Producer', 'Cameo appearance as \"Stroller couple.\"']\n",
      "['1995', 'The Random Factor', 'Director, Writer, Producer', 'Cameo appearance as \"Van Passenger.\"']\n",
      "['1996', 'Dragon Fury II', 'Director', '']\n",
      "['1999', 'Undercover Angel', 'Director, Writer, Producer.', 'Cameo appearance as \"Speedy Messenger.\"']\n",
      "['2004', 'Miss Cast Away', 'Director, Writer, Producer', 'Cameo appearance as \"Courier\"Featuring Michael Jackson.']\n",
      "['2007', 'Light Years Away', 'Director, Writer, Producer', '']\n",
      "['2010', 'First Dog[23]', 'Director, Writer, Producer.', '(Also editor and music supervisor) Cameo appearance as \"Letter Carrier Paul\"Featuring original songs by Dolly Parton']\n",
      "['2014', 'The Amazing Wizard of Paws', 'writer, producer, director, editor']\n",
      "['2017', 'Santa Stole Our Dog', 'writer, producer, director, editor', 'Starring Ed Asner as Santa Claus']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "url = 'https://en.wikipedia.org/wiki/Bryan_Michael_Stoller' #First random search with a table\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "myTable = soup.find('table',{'class':'wikitable'})\n",
    "tbody = myTable.find('tbody')\n",
    "rows = tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    print(cols)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
